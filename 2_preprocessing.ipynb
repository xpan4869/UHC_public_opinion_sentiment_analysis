{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yolandapan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yolandapan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/yolandapan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yolandapan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading required libraries \n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-25_143</td>\n",
       "      <td>ABSOLUTELY a SCAM      I am at the doctor s of...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-23_108</td>\n",
       "      <td>It s not special  I promise you</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-22_129</td>\n",
       "      <td>I noticed Forward is currently hiring on Linke...</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-08_321</td>\n",
       "      <td>Yes gross taxable  pretax investments lower gr...</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-17_211</td>\n",
       "      <td>Regardless  this isn t a sign of a bad company...</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2024-12-08_227</td>\n",
       "      <td>And if you had jumped over the border illegall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2024-11-20_126</td>\n",
       "      <td>I once passed on the sidewalk  Ambulance was c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2024-12-14_149</td>\n",
       "      <td>This is the opposite of the truth   Subsidies ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2024-12-08_268</td>\n",
       "      <td>Not really  My mother was on this plan when sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2024-12-04_172</td>\n",
       "      <td>I m union  my health insurance is free and I p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                               Text  final\n",
       "0    2024-11-25_143  ABSOLUTELY a SCAM      I am at the doctor s of...     -1\n",
       "1    2024-11-23_108                    It s not special  I promise you    -99\n",
       "2    2024-11-22_129  I noticed Forward is currently hiring on Linke...    -99\n",
       "3    2024-12-08_321  Yes gross taxable  pretax investments lower gr...    -99\n",
       "4    2024-12-17_211  Regardless  this isn t a sign of a bad company...    -99\n",
       "..              ...                                                ...    ...\n",
       "995  2024-12-08_227  And if you had jumped over the border illegall...      1\n",
       "996  2024-11-20_126  I once passed on the sidewalk  Ambulance was c...      1\n",
       "997  2024-12-14_149  This is the opposite of the truth   Subsidies ...      1\n",
       "998  2024-12-08_268  Not really  My mother was on this plan when sh...      1\n",
       "999  2024-12-04_172  I m union  my health insurance is free and I p...      1\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the data\n",
    "labeled = pd.read_excel('comments_final.xlsx', usecols=['Date', 'Text', 'final'])\n",
    "labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date     object\n",
       "Text     object\n",
       "final     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special characters have already been removed, need to handle remaining pieces of urls\n",
    "handles = r'_\\w+'\n",
    "labeled['Text'] = labeled['Text'].str.replace(handles, '', regex=True)\n",
    "one_letter_words = r'\\b\\w\\b'\n",
    "labeled['Text'] = labeled['Text'].str.replace(one_letter_words, '', regex=True)\n",
    "words_of_one_letter = r'\\b(\\w)\\1*\\b'\n",
    "labeled['Text'] = labeled['Text'].str.replace(words_of_one_letter, '', regex=True)\n",
    "urls = r'\\b(?:https?)\\s\\S*'  # Match http/https/www followed by non-space characters\n",
    "labeled['Text'] = labeled['Text'].str.replace(urls, '', regex=True)\n",
    "website = r'com'\n",
    "labeled['Text'] = labeled['Text'].str.replace(website, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_map = {\n",
    "    'ǝ': 'e',\n",
    "    'ʇ': 't',\n",
    "    'ı': 'i',\n",
    "    'ɹ': 'r',\n",
    "    'ɔ': 'c',\n",
    "    'ɥ': 'l',\n",
    "    'ʌ': 'v',\n",
    "    'ǝ':'e',\n",
    "    'noʎ': 'y'}\n",
    "\n",
    "# Function to replace flipped characters\n",
    "def replace_flipped_chars(text):\n",
    "    for flipped, normal in flip_map.items():\n",
    "        text = text.replace(flipped, normal)\n",
    "    return text\n",
    "labeled['Text'] = labeled['Text'].apply(replace_flipped_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABSOLUTELY SCAM doctor office right even show credible gave ins Card'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords and tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Filter out stopwords\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Join words back into a sentence\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply the function to a DataFrame column (or individual text)\n",
    "labeled['Text'] = labeled['Text'].apply(remove_stopwords)\n",
    "labeled.iloc[0]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/yolandapan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# lemmatize words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to get the POS tag\n",
    "def get_pos_tag(word):\n",
    "    tag = pos_tag([word])[0][1]\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'  # Noun\n",
    "    elif tag.startswith('V'):\n",
    "        return 'v'  # Verb\n",
    "    elif tag.startswith('J'):\n",
    "        return 'a'  # Adjective\n",
    "    elif tag.startswith('R'):\n",
    "        return 'r'  # Adverb\n",
    "    else:\n",
    "        return 'n'  # Default to noun if no match\n",
    "\n",
    "# Function to lemmatize text with POS tagging\n",
    "def lemmatize_text(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Lemmatize each word with POS tagging\n",
    "    lemmatized_words = [\n",
    "        lemmatizer.lemmatize(word, get_pos_tag(word)) for word in words\n",
    "    ]\n",
    "    \n",
    "    # Join words back into a sentence\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Example DataFrame\n",
    "\n",
    "# Apply the lemmatization function\n",
    "labeled['Text'] = labeled['Text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abd</th>\n",
       "      <th>abdicate</th>\n",
       "      <th>ability</th>\n",
       "      <th>abit</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>youre</th>\n",
       "      <th>yourhealthidaho</th>\n",
       "      <th>youtu</th>\n",
       "      <th>yr</th>\n",
       "      <th>zenni</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zofram</th>\n",
       "      <th>zone</th>\n",
       "      <th>ǝs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3416 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ab  abandon  abd  abdicate  ability  abit  able  abroad  absolute  \\\n",
       "0    0.0      0.0  0.0       0.0      0.0   0.0   0.0     0.0       0.0   \n",
       "1    0.0      0.0  0.0       0.0      0.0   0.0   0.0     0.0       0.0   \n",
       "2    0.0      0.0  0.0       0.0      0.0   0.0   0.0     0.0       0.0   \n",
       "3    0.0      0.0  0.0       0.0      0.0   0.0   0.0     0.0       0.0   \n",
       "4    0.0      0.0  0.0       0.0      0.0   0.0   0.0     0.0       0.0   \n",
       "..   ...      ...  ...       ...      ...   ...   ...     ...       ...   \n",
       "995  0.0      0.0  0.0       0.0      0.0   0.0   0.0     0.0       0.0   \n",
       "996  0.0      0.0  0.0       0.0      0.0   0.0   0.0     0.0       0.0   \n",
       "997  0.0      0.0  0.0       0.0      0.0   0.0   0.0     0.0       0.0   \n",
       "998  0.0      0.0  0.0       0.0      0.0   0.0   0.0     0.0       0.0   \n",
       "999  0.0      0.0  0.0       0.0      0.0   0.0   0.0     0.0       0.0   \n",
       "\n",
       "     absolutely  ...  youre  yourhealthidaho  youtu   yr  zenni      zero  \\\n",
       "0      0.328537  ...    0.0              0.0    0.0  0.0    0.0  0.000000   \n",
       "1      0.000000  ...    0.0              0.0    0.0  0.0    0.0  0.000000   \n",
       "2      0.000000  ...    0.0              0.0    0.0  0.0    0.0  0.135178   \n",
       "3      0.000000  ...    0.0              0.0    0.0  0.0    0.0  0.000000   \n",
       "4      0.000000  ...    0.0              0.0    0.0  0.0    0.0  0.000000   \n",
       "..          ...  ...    ...              ...    ...  ...    ...       ...   \n",
       "995    0.000000  ...    0.0              0.0    0.0  0.0    0.0  0.000000   \n",
       "996    0.000000  ...    0.0              0.0    0.0  0.0    0.0  0.000000   \n",
       "997    0.000000  ...    0.0              0.0    0.0  0.0    0.0  0.000000   \n",
       "998    0.000000  ...    0.0              0.0    0.0  0.0    0.0  0.196500   \n",
       "999    0.000000  ...    0.0              0.0    0.0  0.0    0.0  0.000000   \n",
       "\n",
       "     zip  zofram  zone   ǝs  \n",
       "0    0.0     0.0   0.0  0.0  \n",
       "1    0.0     0.0   0.0  0.0  \n",
       "2    0.0     0.0   0.0  0.0  \n",
       "3    0.0     0.0   0.0  0.0  \n",
       "4    0.0     0.0   0.0  0.0  \n",
       "..   ...     ...   ...  ...  \n",
       "995  0.0     0.0   0.0  0.0  \n",
       "996  0.0     0.0   0.0  0.0  \n",
       "997  0.0     0.0   0.0  0.0  \n",
       "998  0.0     0.0   0.0  0.0  \n",
       "999  0.0     0.0   0.0  0.0  \n",
       "\n",
       "[1000 rows x 3416 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(labeled['Text'])\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.to_csv(\"cleaned_labeled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3416)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature matrix of vectorized corpus\n",
    "tfidf_df.shape\n",
    "# 1000 posts, 3412 unique features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ab', 'abandon', 'abd', ..., 'zofram', 'zone', 'ǝs'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please</td>\n",
       "      <td>41.853787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insurance</td>\n",
       "      <td>39.863921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plan</td>\n",
       "      <td>31.729651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get</td>\n",
       "      <td>26.718189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>post</td>\n",
       "      <td>22.598333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thank</td>\n",
       "      <td>22.466427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>question</td>\n",
       "      <td>21.735177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>state</td>\n",
       "      <td>21.608627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>go</td>\n",
       "      <td>21.577287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>reddit</td>\n",
       "      <td>21.326011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  frequency\n",
       "0     please  41.853787\n",
       "1  insurance  39.863921\n",
       "2       plan  31.729651\n",
       "3        get  26.718189\n",
       "4       post  22.598333\n",
       "5      thank  22.466427\n",
       "6   question  21.735177\n",
       "7      state  21.608627\n",
       "8         go  21.577287\n",
       "9     reddit  21.326011"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Order features by frequency\n",
    "def get_topn_features(X, feature_names, topn=10):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        X: feature matrix\n",
    "        feature_names: extracted features during vectorization\n",
    "        topn: the number of most frequent features to return\n",
    "    Outputs:\n",
    "        topn most frequent features and their frequency\n",
    "    \"\"\"\n",
    "    feature_ct = np.asarray(np.sum(X, axis=0)).reshape(-1)\n",
    "\n",
    "    feature_freq = []\n",
    "    \n",
    "    for i in np.argsort(feature_ct)[::-1][:topn]:\n",
    "        feature_freq.append({'feature':feature_names[i], 'frequency':feature_ct[i]})\n",
    "    \n",
    "    return pd.DataFrame(feature_freq)\n",
    "\n",
    "get_topn_features(tfidf_df, feature_names, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Word  TF-IDF Sum\n",
      "2246      please   41.853787\n",
      "1513   insurance   39.863921\n",
      "2234        plan   31.729651\n",
      "1235         get   26.718189\n",
      "2286        post   22.598333\n",
      "...          ...         ...\n",
      "764   descendant    0.046968\n",
      "1203    fulltime    0.046968\n",
      "2519      relies    0.046968\n",
      "55      adoption    0.046968\n",
      "3361    withheld    0.046968\n",
      "\n",
      "[3416 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Order features by tfidf score\n",
    "\n",
    "# Get the sum of the TF-IDF scores for each word (across all documents)\n",
    "tfidf_sum = X.sum(axis=0).A1  # Flatten the matrix to a 1D array\n",
    "\n",
    "# Create a DataFrame to easily inspect the words and their total TF-IDF scores\n",
    "df = pd.DataFrame({'Word': feature_names, 'TF-IDF Sum': tfidf_sum})\n",
    "\n",
    "# Sort by the sum of the TF-IDF scores (descending order)\n",
    "df_sorted_by_tfidf = df.sort_values(by='TF-IDF Sum', ascending=False)\n",
    "\n",
    "print(df_sorted_by_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the remaining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-20_1</td>\n",
       "      <td>If your previous providers used epic software ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-20_2</td>\n",
       "      <td>So here s the thing  If you claim your fiancee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-20_3</td>\n",
       "      <td>I really don t have much advice to add as I ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-20_4</td>\n",
       "      <td>Well  they made around   k year  but my dad is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-20_5</td>\n",
       "      <td>I signed up for them too without doing researc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6013</th>\n",
       "      <td>2024-12-17_277</td>\n",
       "      <td>No  there s no legal requirement for an unpaid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>2024-12-17_278</td>\n",
       "      <td>You are very alone in that opinion which is wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6015</th>\n",
       "      <td>2024-12-17_279</td>\n",
       "      <td>The same as any other post obamacare health in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016</th>\n",
       "      <td>2024-12-17_280</td>\n",
       "      <td>Thank you for your submission   u AnythingNext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>2024-12-17_281</td>\n",
       "      <td>How was prescription coverage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6018 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID                                               Text\n",
       "0       2024-11-20_1  If your previous providers used epic software ...\n",
       "1       2024-11-20_2  So here s the thing  If you claim your fiancee...\n",
       "2       2024-11-20_3  I really don t have much advice to add as I ve...\n",
       "3       2024-11-20_4  Well  they made around   k year  but my dad is...\n",
       "4       2024-11-20_5  I signed up for them too without doing researc...\n",
       "...              ...                                                ...\n",
       "6013  2024-12-17_277  No  there s no legal requirement for an unpaid...\n",
       "6014  2024-12-17_278  You are very alone in that opinion which is wh...\n",
       "6015  2024-12-17_279  The same as any other post obamacare health in...\n",
       "6016  2024-12-17_280  Thank you for your submission   u AnythingNext...\n",
       "6017  2024-12-17_281                      How was prescription coverage\n",
       "\n",
       "[6018 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the data\n",
    "unlabeled = pd.read_csv('filtered_comments.csv')\n",
    "unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12036"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled.size\n",
    "# 12,036 comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID      object\n",
       "Text    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special characters have already been removed, need to handle remaining pieces of urls\n",
    "handles = r'_\\w+'\n",
    "unlabeled['Text'] = unlabeled['Text'].str.replace(handles, '', regex=True)\n",
    "one_letter_words = r'\\b\\w\\b'\n",
    "unlabeled['Text'] = unlabeled['Text'].str.replace(one_letter_words, '', regex=True)\n",
    "words_of_one_letter = r'\\b(\\w)\\1*\\b'\n",
    "unlabeled['Text'] = unlabeled['Text'].str.replace(words_of_one_letter, '', regex=True)\n",
    "urls = r'\\b(?:https?)\\s\\S*'  # Match http/https/www followed by non-space characters\n",
    "unlabeled['Text'] = unlabeled['Text'].str.replace(urls, '', regex=True)\n",
    "website = r'com'\n",
    "unlabeled['Text'] = unlabeled['Text'].str.replace(website, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled['Text'] = unlabeled['Text'].apply(replace_flipped_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_text(text):\n",
    "    return ''.join([unicodedata.normalize('NFKD', char) for char in text])\n",
    "unlabeled['Text'] = unlabeled['Text'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled['Text'] = unlabeled['Text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled['Text'] = unlabeled['Text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aad</th>\n",
       "      <th>aarp</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>abalone</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abb</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcbb</th>\n",
       "      <th>abd</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>zirconium</th>\n",
       "      <th>znome</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zolpidem</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zuchuu</th>\n",
       "      <th>zumbaand</th>\n",
       "      <th>ǝs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6013</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6015</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6016</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6018 rows × 8655 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aad  aarp   ab  aba  abalone  abandon  abb  abc  abcbb  abd  ...  \\\n",
       "0     0.0   0.0  0.0  0.0      0.0      0.0  0.0  0.0    0.0  0.0  ...   \n",
       "1     0.0   0.0  0.0  0.0      0.0      0.0  0.0  0.0    0.0  0.0  ...   \n",
       "2     0.0   0.0  0.0  0.0      0.0      0.0  0.0  0.0    0.0  0.0  ...   \n",
       "3     0.0   0.0  0.0  0.0      0.0      0.0  0.0  0.0    0.0  0.0  ...   \n",
       "4     0.0   0.0  0.0  0.0      0.0      0.0  0.0  0.0    0.0  0.0  ...   \n",
       "...   ...   ...  ...  ...      ...      ...  ...  ...    ...  ...  ...   \n",
       "6013  0.0   0.0  0.0  0.0      0.0      0.0  0.0  0.0    0.0  0.0  ...   \n",
       "6014  0.0   0.0  0.0  0.0      0.0      0.0  0.0  0.0    0.0  0.0  ...   \n",
       "6015  0.0   0.0  0.0  0.0      0.0      0.0  0.0  0.0    0.0  0.0  ...   \n",
       "6016  0.0   0.0  0.0  0.0      0.0      0.0  0.0  0.0    0.0  0.0  ...   \n",
       "6017  0.0   0.0  0.0  0.0      0.0      0.0  0.0  0.0    0.0  0.0  ...   \n",
       "\n",
       "      zipcode  zirconium  znome  zodiac  zolpidem  zoo  zucchini  zuchuu  \\\n",
       "0         0.0        0.0    0.0     0.0       0.0  0.0       0.0     0.0   \n",
       "1         0.0        0.0    0.0     0.0       0.0  0.0       0.0     0.0   \n",
       "2         0.0        0.0    0.0     0.0       0.0  0.0       0.0     0.0   \n",
       "3         0.0        0.0    0.0     0.0       0.0  0.0       0.0     0.0   \n",
       "4         0.0        0.0    0.0     0.0       0.0  0.0       0.0     0.0   \n",
       "...       ...        ...    ...     ...       ...  ...       ...     ...   \n",
       "6013      0.0        0.0    0.0     0.0       0.0  0.0       0.0     0.0   \n",
       "6014      0.0        0.0    0.0     0.0       0.0  0.0       0.0     0.0   \n",
       "6015      0.0        0.0    0.0     0.0       0.0  0.0       0.0     0.0   \n",
       "6016      0.0        0.0    0.0     0.0       0.0  0.0       0.0     0.0   \n",
       "6017      0.0        0.0    0.0     0.0       0.0  0.0       0.0     0.0   \n",
       "\n",
       "      zumbaand   ǝs  \n",
       "0          0.0  0.0  \n",
       "1          0.0  0.0  \n",
       "2          0.0  0.0  \n",
       "3          0.0  0.0  \n",
       "4          0.0  0.0  \n",
       "...        ...  ...  \n",
       "6013       0.0  0.0  \n",
       "6014       0.0  0.0  \n",
       "6015       0.0  0.0  \n",
       "6016       0.0  0.0  \n",
       "6017       0.0  0.0  \n",
       "\n",
       "[6018 rows x 8655 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer()\n",
    "Y = vect.fit_transform(unlabeled['Text'])\n",
    "tfidf_df2 = pd.DataFrame(Y.toarray(), columns=vect.get_feature_names_out())\n",
    "tfidf_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df2.to_csv(\"cleaned_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aad', 'aarp', 'ab', ..., 'zuchuu', 'zumbaand', 'ǝs'], dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please</td>\n",
       "      <td>263.743131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insurance</td>\n",
       "      <td>223.342509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plan</td>\n",
       "      <td>178.732110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>post</td>\n",
       "      <td>143.006348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>question</td>\n",
       "      <td>142.123183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get</td>\n",
       "      <td>141.507610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>state</td>\n",
       "      <td>135.640810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reddit</td>\n",
       "      <td>134.709868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>healthinsurance</td>\n",
       "      <td>133.142612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>solicitation</td>\n",
       "      <td>131.722852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature   frequency\n",
       "0           please  263.743131\n",
       "1        insurance  223.342509\n",
       "2             plan  178.732110\n",
       "3             post  143.006348\n",
       "4         question  142.123183\n",
       "5              get  141.507610\n",
       "6            state  135.640810\n",
       "7           reddit  134.709868\n",
       "8  healthinsurance  133.142612\n",
       "9     solicitation  131.722852"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topn_features(tfidf_df2, feature_names, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled['Date'] = labeled['Date'].str.split('_').str[0]  # Keep YYYY-MM-DD\n",
    "labeled = labeled.drop('ID', axis=1, errors='ignore')  # Drop ID if exists\n",
    "\n",
    "unlabeled['Date'] = unlabeled['ID'].str.split('_').str[0]  # Keep YYYY-MM-DD\n",
    "unlabeled = unlabeled.drop('ID', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_texts = pd.concat([labeled, unlabeled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>ABSOLUTELY SCAM doctor office right even show ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-23</td>\n",
       "      <td>special promise</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>notice Forward currently hire Linkedin make ze...</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-08</td>\n",
       "      <td>Yes gross taxable pretax investment low gross ...</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-17</td>\n",
       "      <td>Regardless sign bad pany could state require</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               Text  final\n",
       "0  2024-11-25  ABSOLUTELY SCAM doctor office right even show ...   -1.0\n",
       "1  2024-11-23                                    special promise  -99.0\n",
       "2  2024-11-22  notice Forward currently hire Linkedin make ze...  -99.0\n",
       "3  2024-12-08  Yes gross taxable pretax investment low gross ...  -99.0\n",
       "4  2024-12-17       Regardless sign bad pany could state require  -99.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_raw_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = r'_\\w+'\n",
    "all_raw_texts['Text'] = all_raw_texts['Text'].str.replace(handles, '', regex=True)\n",
    "one_letter_words = r'\\b\\w\\b'\n",
    "all_raw_texts['Text'] = all_raw_texts['Text'].str.replace(one_letter_words, '', regex=True)\n",
    "words_of_one_letter = r'\\b(\\w)\\1*\\b'\n",
    "all_raw_texts['Text'] = all_raw_texts['Text'].str.replace(words_of_one_letter, '', regex=True)\n",
    "urls = r'\\b(?:https?)\\s\\S*'  # Match http/https/www followed by non-space characters\n",
    "all_raw_texts['Text'] = all_raw_texts['Text'].str.replace(urls, '', regex=True)\n",
    "website = r'com'\n",
    "all_raw_texts['Text'] = all_raw_texts['Text'].str.replace(website, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_texts['Text'] = all_raw_texts['Text'].apply(replace_flipped_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_texts['Text'] = all_raw_texts['Text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_texts['Text'] = all_raw_texts['Text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>aca</th>\n",
       "      <th>aca marketplace</th>\n",
       "      <th>aca plan</th>\n",
       "      <th>aca pliant</th>\n",
       "      <th>aca subsidy</th>\n",
       "      <th>accept</th>\n",
       "      <th>accept medicaid</th>\n",
       "      <th>...</th>\n",
       "      <th>year ago</th>\n",
       "      <th>year old</th>\n",
       "      <th>year work</th>\n",
       "      <th>year year</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.441754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7014</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7015</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7016</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7018 rows × 1576 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ability  able  absolutely  aca  aca marketplace  aca plan  aca pliant  \\\n",
       "0         0.0   0.0    0.406282  0.0              0.0       0.0         0.0   \n",
       "1         0.0   0.0    0.000000  0.0              0.0       0.0         0.0   \n",
       "2         0.0   0.0    0.000000  0.0              0.0       0.0         0.0   \n",
       "3         0.0   0.0    0.000000  0.0              0.0       0.0         0.0   \n",
       "4         0.0   0.0    0.000000  0.0              0.0       0.0         0.0   \n",
       "...       ...   ...         ...  ...              ...       ...         ...   \n",
       "7013      0.0   0.0    0.000000  0.0              0.0       0.0         0.0   \n",
       "7014      0.0   0.0    0.000000  0.0              0.0       0.0         0.0   \n",
       "7015      0.0   0.0    0.000000  0.0              0.0       0.0         0.0   \n",
       "7016      0.0   0.0    0.000000  0.0              0.0       0.0         0.0   \n",
       "7017      0.0   0.0    0.000000  0.0              0.0       0.0         0.0   \n",
       "\n",
       "      aca subsidy  accept  accept medicaid  ...  year ago  year old  \\\n",
       "0             0.0     0.0              0.0  ...       0.0       0.0   \n",
       "1             0.0     0.0              0.0  ...       0.0       0.0   \n",
       "2             0.0     0.0              0.0  ...       0.0       0.0   \n",
       "3             0.0     0.0              0.0  ...       0.0       0.0   \n",
       "4             0.0     0.0              0.0  ...       0.0       0.0   \n",
       "...           ...     ...              ...  ...       ...       ...   \n",
       "7013          0.0     0.0              0.0  ...       0.0       0.0   \n",
       "7014          0.0     0.0              0.0  ...       0.0       0.0   \n",
       "7015          0.0     0.0              0.0  ...       0.0       0.0   \n",
       "7016          0.0     0.0              0.0  ...       0.0       0.0   \n",
       "7017          0.0     0.0              0.0  ...       0.0       0.0   \n",
       "\n",
       "      year work  year year  yearly  yep       yes  york  young      zero  \n",
       "0           0.0        0.0     0.0  0.0  0.000000   0.0    0.0  0.000000  \n",
       "1           0.0        0.0     0.0  0.0  0.000000   0.0    0.0  0.000000  \n",
       "2           0.0        0.0     0.0  0.0  0.000000   0.0    0.0  0.184591  \n",
       "3           0.0        0.0     0.0  0.0  0.441754   0.0    0.0  0.000000  \n",
       "4           0.0        0.0     0.0  0.0  0.000000   0.0    0.0  0.000000  \n",
       "...         ...        ...     ...  ...       ...   ...    ...       ...  \n",
       "7013        0.0        0.0     0.0  0.0  0.000000   0.0    0.0  0.000000  \n",
       "7014        0.0        0.0     0.0  0.0  0.000000   0.0    0.0  0.000000  \n",
       "7015        0.0        0.0     0.0  0.0  0.000000   0.0    0.0  0.000000  \n",
       "7016        0.0        0.0     0.0  0.0  0.000000   0.0    0.0  0.000000  \n",
       "7017        0.0        0.0     0.0  0.0  0.000000   0.0    0.0  0.000000  \n",
       "\n",
       "[7018 rows x 1576 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df= 0.002,\n",
    "                             max_df= 0.95,    \n",
    "                             stop_words='english',\n",
    "                             ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(all_raw_texts['Text'])\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.to_csv(\"cleaned_total_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7018"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ability', 'able', 'absolutely', ..., 'york', 'young', 'zero'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>insurance</td>\n",
       "      <td>286.359295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plan</td>\n",
       "      <td>225.630043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pay</td>\n",
       "      <td>161.106092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>state</td>\n",
       "      <td>158.277136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>post</td>\n",
       "      <td>157.722957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>question</td>\n",
       "      <td>151.148457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reddit</td>\n",
       "      <td>142.961872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>healthinsurance</td>\n",
       "      <td>138.359111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thank</td>\n",
       "      <td>138.218248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>solicitation</td>\n",
       "      <td>136.587912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature   frequency\n",
       "0        insurance  286.359295\n",
       "1             plan  225.630043\n",
       "2              pay  161.106092\n",
       "3            state  158.277136\n",
       "4             post  157.722957\n",
       "5         question  151.148457\n",
       "6           reddit  142.961872\n",
       "7  healthinsurance  138.359111\n",
       "8            thank  138.218248\n",
       "9     solicitation  136.587912"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Order features by frequency\n",
    "def get_topn_features(X, feature_names, topn=10):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        X: feature matrix\n",
    "        feature_names: extracted features during vectorization\n",
    "        topn: the number of most frequent features to return\n",
    "    Outputs:\n",
    "        topn most frequent features and their frequency\n",
    "    \"\"\"\n",
    "    feature_ct = np.asarray(np.sum(X, axis=0)).reshape(-1)\n",
    "\n",
    "    feature_freq = []\n",
    "    \n",
    "    for i in np.argsort(feature_ct)[::-1][:topn]:\n",
    "        feature_freq.append({'feature':feature_names[i], 'frequency':feature_ct[i]})\n",
    "    \n",
    "    return pd.DataFrame(feature_freq)\n",
    "\n",
    "get_topn_features(tfidf_df, feature_names, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Word  TF-IDF Sum\n",
      "671           insurance  286.359295\n",
      "1043               plan  225.630043\n",
      "994                 pay  161.106092\n",
      "1379              state  158.277136\n",
      "1095               post  157.722957\n",
      "...                 ...         ...\n",
      "355      different plan    2.868763\n",
      "834        medical plan    2.815636\n",
      "685   insurance network    2.719281\n",
      "1404    submission read    2.520426\n",
      "1568          year work    2.453891\n",
      "\n",
      "[1576 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Order features by tfidf score\n",
    "\n",
    "# Get the sum of the TF-IDF scores for each word (across all documents)\n",
    "tfidf_sum = X.sum(axis=0).A1  # Flatten the matrix to a 1D array\n",
    "\n",
    "# Create a DataFrame to easily inspect the words and their total TF-IDF scores\n",
    "df = pd.DataFrame({'Word': feature_names, 'TF-IDF Sum': tfidf_sum})\n",
    "\n",
    "# Sort by the sum of the TF-IDF scores (descending order)\n",
    "df_sorted_by_tfidf = df.sort_values(by='TF-IDF Sum', ascending=False)\n",
    "\n",
    "print(df_sorted_by_tfidf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_mod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
